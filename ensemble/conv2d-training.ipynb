{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "736c5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, LambdaLR\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "from adamp import AdamP\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "import mlflow\n",
    "remote_server_uri = \"http://175.41.216.32:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(\"seti-mizo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "fc5579ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    apex=False\n",
    "    debug=False\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name='eca_nfnet_l0'\n",
    "    size=512\n",
    "    scheduler='ReduceLROnPlateau' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    criterion = 'BCE'\n",
    "    epochs=15 #15or20\n",
    "    factor=0.2 # ReduceLROnPlateau\n",
    "    patience=2 # ReduceLROnPlateau\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    #T_max=15# CosineAnnealingLR\n",
    "    #T_0=20 # CosineAnnealingWarmRestarts\n",
    "    lr=5e-3\n",
    "    min_lr=1e-6\n",
    "    batch_size=128\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    target_size=1\n",
    "    target_col='target'\n",
    "    n_fold=5\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    mix_up=False # True or False\n",
    "    cut_mix=False # True or False\n",
    "    sam =True\n",
    "    warmup_epochs=0\n",
    "    multiplier=10\n",
    "    multisample_dropout=False\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "e1f2375a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>file_path</th>\n",
       "      <th>fold</th>\n",
       "      <th>l0_pred</th>\n",
       "      <th>b0_ns_pred</th>\n",
       "      <th>b3_ns_pred</th>\n",
       "      <th>b3_ns_w_pred</th>\n",
       "      <th>v2_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000cd479c2106d4</td>\n",
       "      <td>0</td>\n",
       "      <td>seti-breakthrough-listen/train/0/000cd479c2106...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118882</td>\n",
       "      <td>0.052386</td>\n",
       "      <td>0.065241</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.040911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00104dc954c2d30</td>\n",
       "      <td>0</td>\n",
       "      <td>seti-breakthrough-listen/train/0/00104dc954c2d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.005478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00154729d2fd371</td>\n",
       "      <td>0</td>\n",
       "      <td>seti-breakthrough-listen/train/0/00154729d2fd3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.029937</td>\n",
       "      <td>0.020490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001f88b77b9b373</td>\n",
       "      <td>0</td>\n",
       "      <td>seti-breakthrough-listen/train/0/001f88b77b9b3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092242</td>\n",
       "      <td>0.078834</td>\n",
       "      <td>0.105646</td>\n",
       "      <td>0.121659</td>\n",
       "      <td>0.113246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021fc57e231440</td>\n",
       "      <td>0</td>\n",
       "      <td>seti-breakthrough-listen/train/0/0021fc57e2314...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065024</td>\n",
       "      <td>0.050495</td>\n",
       "      <td>0.049544</td>\n",
       "      <td>0.066693</td>\n",
       "      <td>0.055329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  target                                          file_path  \\\n",
       "0  000cd479c2106d4       0  seti-breakthrough-listen/train/0/000cd479c2106...   \n",
       "1  00104dc954c2d30       0  seti-breakthrough-listen/train/0/00104dc954c2d...   \n",
       "2  00154729d2fd371       0  seti-breakthrough-listen/train/0/00154729d2fd3...   \n",
       "3  001f88b77b9b373       0  seti-breakthrough-listen/train/0/001f88b77b9b3...   \n",
       "4  0021fc57e231440       0  seti-breakthrough-listen/train/0/0021fc57e2314...   \n",
       "\n",
       "   fold   l0_pred  b0_ns_pred  b3_ns_pred  b3_ns_w_pred   v2_pred  \n",
       "0     0  0.118882    0.052386    0.065241      0.043430  0.040911  \n",
       "1     0  0.007711    0.007562    0.009747      0.008566  0.005478  \n",
       "2     0  0.029970    0.032488    0.018109      0.029937  0.020490  \n",
       "3     0  0.092242    0.078834    0.105646      0.121659  0.113246  \n",
       "4     0  0.065024    0.050495    0.049544      0.066693  0.055329  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>l0_pred</th>\n",
       "      <th>b0_ns_pred</th>\n",
       "      <th>b3_ns_pred</th>\n",
       "      <th>b3_ns_w_pred</th>\n",
       "      <th>v2_pred</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bf832cae9ff1</td>\n",
       "      <td>0.057992</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.083506</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>seti-breakthrough-listen/test/0/000bf832cae9ff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c74cc71a1140</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>0.075789</td>\n",
       "      <td>0.060592</td>\n",
       "      <td>0.092812</td>\n",
       "      <td>0.046926</td>\n",
       "      <td>seti-breakthrough-listen/test/0/000c74cc71a114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000f5f9851161d3</td>\n",
       "      <td>0.057835</td>\n",
       "      <td>0.055594</td>\n",
       "      <td>0.056416</td>\n",
       "      <td>0.076440</td>\n",
       "      <td>0.049687</td>\n",
       "      <td>seti-breakthrough-listen/test/0/000f5f9851161d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000f7499e95aba6</td>\n",
       "      <td>0.088791</td>\n",
       "      <td>0.094974</td>\n",
       "      <td>0.097937</td>\n",
       "      <td>0.123739</td>\n",
       "      <td>0.113162</td>\n",
       "      <td>seti-breakthrough-listen/test/0/000f7499e95aba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00133ce6ec257f9</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>0.066846</td>\n",
       "      <td>0.058025</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.046930</td>\n",
       "      <td>seti-breakthrough-listen/test/0/00133ce6ec257f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   l0_pred  b0_ns_pred  b3_ns_pred  b3_ns_w_pred   v2_pred  \\\n",
       "0  000bf832cae9ff1  0.057992    0.050963    0.055040      0.083506  0.048063   \n",
       "1  000c74cc71a1140  0.062372    0.075789    0.060592      0.092812  0.046926   \n",
       "2  000f5f9851161d3  0.057835    0.055594    0.056416      0.076440  0.049687   \n",
       "3  000f7499e95aba6  0.088791    0.094974    0.097937      0.123739  0.113162   \n",
       "4  00133ce6ec257f9  0.062838    0.066846    0.058025      0.085500  0.046930   \n",
       "\n",
       "                                           file_path  \n",
       "0  seti-breakthrough-listen/test/0/000bf832cae9ff...  \n",
       "1  seti-breakthrough-listen/test/0/000c74cc71a114...  \n",
       "2  seti-breakthrough-listen/test/0/000f5f9851161d...  \n",
       "3  seti-breakthrough-listen/test/0/000f7499e95aba...  \n",
       "4  seti-breakthrough-listen/test/0/00133ce6ec257f...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('meta_train.csv')\n",
    "#train_old = pd.read_csv('seti-breakthrough-listen/old_leaky_data/train_labels_old.csv')\n",
    "\n",
    "test = pd.read_csv('meta_test.csv')\n",
    "\n",
    "def get_train_file_path(image_id):\n",
    "    return \"seti-breakthrough-listen/train/{}/{}.npy\".format(image_id[0], image_id)\n",
    "\"\"\"\n",
    "def get_train__old_file_path(image_id):\n",
    "    return \"seti-breakthrough-listen/old_leaky_data/train_old/{}/{}.npy\".format(image_id[0], image_id)\n",
    "\"\"\"\n",
    "\n",
    "def get_test_file_path(image_id):\n",
    "    return \"seti-breakthrough-listen/test/{}/{}.npy\".format(image_id[0], image_id)\n",
    "\n",
    "train['file_path'] = train['id'].apply(get_train_file_path)\n",
    "test['file_path'] = test['id'].apply(get_test_file_path)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1389e795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 5)\n"
     ]
    }
   ],
   "source": [
    "x=np.array(train.drop(columns=['id','target','file_path','fold']))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "847b4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 5)\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape((len(train), -1))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "3e679f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape(60000, 1, 1, 5)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "38864b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(train['target'])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "171023ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ed976874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = roc_auc_score(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c6b5eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "f92ff39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn2dClassifier(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(Cnn2dClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=(1,1), stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=(1,1), stride=1, padding=0)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.layer_1 = nn.utils.weight_norm(nn.Linear(1280, 1280))\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc = nn.Linear(1280, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        #print(x.shape)\n",
    " \n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "bac594a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "        \n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "                self.state[p][\"e_w\"] = e_w\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        p.grad.norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a95ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n",
      "Training with FOLD0 started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677dac8425df466998f01832adf072be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5: | Train Loss: 0.15956 |            Val Loss: 0.15679 | Train Acc: 0.00000|            Val Acc: 0.00000\n",
      "Epoch  10: | Train Loss: 0.15931 |            Val Loss: 0.15678 | Train Acc: 0.00000|            Val Acc: 0.00000\n",
      "Epoch  15: | Train Loss: 0.15923 |            Val Loss: 0.15677 | Train Acc: 0.00000|            Val Acc: 0.00000\n",
      "Epoch  20: | Train Loss: 0.15947 |            Val Loss: 0.15677 | Train Acc: 0.00000|            Val Acc: 0.00000\n",
      "Epoch  25: | Train Loss: 0.15954 |            Val Loss: 0.15676 | Train Acc: 0.00000|            Val Acc: 0.00000\n",
      "Epoch  30: | Train Loss: 0.15925 |            Val Loss: 0.15676 | Train Acc: 0.00000|            Val Acc: 0.00000\n",
      "Epoch  35: | Train Loss: 0.15940 |            Val Loss: 0.15675 | Train Acc: 0.00000|            Val Acc: 0.00000\n",
      "Epoch  40: | Train Loss: 0.15906 |            Val Loss: 0.15675 | Train Acc: 0.00000|            Val Acc: 0.00000\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, \n",
    "                        random_state=42).split(X, y)\n",
    "total_acc=0.0\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    accuracy_stats = { 'train': [], \"val\": [] }\n",
    "    loss_stats = { 'train': [], \"val\": [] }\n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    #if fold > 0:\n",
    "    #    break \n",
    "\n",
    "    print('Training with FOLD{} started'.format(fold))\n",
    "    \n",
    "    X_train  = x[trn_idx]\n",
    "    y_train  = y[trn_idx]\n",
    "    \n",
    "    X_val  = x[val_idx]\n",
    "    y_val  = y[val_idx]  \n",
    "    \n",
    "    train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(),torch.from_numpy(y_train).float())\n",
    "    val_dataset = ClassifierDataset(torch.from_numpy(X_val).float(),torch.from_numpy(y_val).float())\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=CFG.batch_size) #sampler=weighted_sampler\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=CFG.batch_size)\n",
    "    \n",
    "    iters = len(train_loader)\n",
    "    \n",
    "    model = Cnn2dClassifier(num_feature = 5, num_class=1)\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-6)\n",
    "    optimizer = AdamP(model.parameters(), lr=7e-3, weight_decay=1e-6)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    #scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=1, eta_min=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                       factor=0.75, patience=5, threshold=1e-5, threshold_mode='rel',\n",
    "                                                       cooldown=3, min_lr=1e-8, eps=1e-08, verbose=False)\n",
    "    optimizer.zero_grad()\n",
    "    for e in tqdm(range(1, 51)):\n",
    "        ## TRAINING\n",
    "        train_epoch_loss = 0\n",
    "        train_epoch_acc = 0\n",
    "        timage_preds_all = []\n",
    "        timage_targets_all = []\n",
    "        \n",
    "        model.train()\n",
    "        for i, (X_train_batch, y_train_batch) in enumerate(train_loader):\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            y_train_pred = model(X_train_batch)\n",
    "            #print(y_train_pred)\n",
    "            train_loss = criterion(y_train_pred.view(-1), y_train_batch)\n",
    "            loss = train_loss\n",
    "            train_acc = get_score(y_train_batch,y_train_pred.sigmoid().detach().cpu().numpy())\n",
    "            timage_preds_all += [y_train_pred.sigmoid().detach().cpu().numpy()]\n",
    "            timage_targets_all += [y_train_batch.detach().cpu().numpy()]\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step(train_loss)\n",
    "            scheduler.step(e + i / iters)\n",
    "\n",
    "            # log results\n",
    "            train_epoch_loss += loss.item()\n",
    "            #train_epoch_acc += train_acc.item()\n",
    "        \n",
    "        timage_preds_all = np.concatenate(timage_preds_all)\n",
    "        timage_targets_all = np.concatenate(timage_targets_all)\n",
    "        #print('train accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
    "        \n",
    "        ## VALIDATION    \n",
    "        with torch.no_grad():\n",
    "            val_epoch_loss = 0\n",
    "            val_epoch_acc = 0\n",
    "            model.eval()\n",
    "            image_preds_all = []\n",
    "            image_targets_all = []\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch,y_val_batch = X_val_batch.to(device), y_val_batch.to(device)    \n",
    "                y_val_pred = model(X_val_batch)\n",
    "                val_loss = criterion(y_val_pred.view(-1), y_val_batch)\n",
    "                loss = val_loss             \n",
    "\n",
    "                #val_acc = get_score(y_val_pred, y_val_batch)\n",
    "                image_preds_all += [y_val_pred.sigmoid().to('cpu').numpy()]\n",
    "                image_targets_all += [y_val_batch.detach().cpu().numpy()]\n",
    "                \n",
    "                # log results\n",
    "                val_epoch_loss += loss.item()\n",
    "                \n",
    "        image_preds_all = np.concatenate(image_preds_all)\n",
    "        image_targets_all = np.concatenate(image_targets_all)\n",
    "        #print('validation accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
    "\n",
    "        #scheduler.step(val_epoch_loss/len(val_loader))\n",
    "\n",
    "        loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "        loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "        accuracy_stats['train'].append((timage_preds_all==timage_targets_all).mean())\n",
    "        accuracy_stats['val'].append((image_preds_all==image_targets_all).mean())\n",
    "\n",
    "        if(image_preds_all==image_targets_all).mean() > best_val_acc:\n",
    "            \n",
    "            torch.save(model.state_dict(), f'MetaClassifier_{fold}_best.pth')\n",
    "            best_val_acc = (image_preds_all==image_targets_all).mean()\n",
    "            print(f'Save Model Acc:{best_val_acc:.5f} Epoch:{e}')\n",
    "            best_epoch = e\n",
    "\n",
    "        if (e % 5) == 0:\n",
    "            print(f'Epoch {e+0:3}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} |\\\n",
    "            Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {(timage_preds_all==timage_targets_all).mean():.5f}|\\\n",
    "            Val Acc: {(image_preds_all==image_targets_all).mean():.5f}')\n",
    "    total_acc += best_val_acc\n",
    "    \n",
    "print('Fold Ensemble Accuracy== {:.5f}'.format(total_acc/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b050a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
